{# Fields required for this template:

- class_name: str. The name of the class to be created
- inherits_from: str. The name of the class this class inherits from
- definition: Dict[str, str]. A dictionary of the fields and their types.
- defaults: Dict[str, str]. A dictionary of the fields and their default values. If no default value is specified, the field is required.
- imports: Dict[str, str]. A dictionary of the imports to be added to the file. The key is the name of the import, the value is the import itself.

#}

# The following file has been created automatically based on a jinja template
# Anything you modify to it, will get lost when the next time the template is
# created. If you want to modify the class, please do so in the template
#
# Template has been rendered

{# Dict of required keys-vals, these have no defaults so they need to be handled differently #}
{% set required = {} %}

import uuid
import tomlkit

from pathlib import Path
from typing import List, Tuple, Dict, Optional, Union
{% for key, val in imports.items() -%}
{{ val }} as {{ key }}
{% endfor %}
{% if class_name == 'Instance' -%}
from labcore.data.datadict_storage import datadict_from_hdf5
{% endif -%}

from qdata.utils import create_timestamp
from qdata.components import Comment, SupportedCommentType, Table



class {{class_name}}({{ inherits_from }}):
    def __init__(self,
                 {% for key, val in definition.items() -%}
                 {# This is to check what items should not have default and need to come before any other argument #}
                 {%- if key not in defaults -%}
                 {{ key }}: {{ val }},
                 {% do required.update({key: val}) -%}
                 {% endif -%}
                 {% endfor -%}
                 {% for key in required.keys() -%}
                 {% do definition.pop(key) -%}
                 {% endfor -%}
                 {% for key, val in definition.items() -%}
                 {% if 'time' in key -%}
                 {{ key }}: str = None,
                 {% else -%}
                 {{ key }}: {{ val }} = {{ defaults[key] }},
                 {% endif -%}
                 {% endfor -%}
                 {% if class_name != 'Entity' -%}
                 *args, **kwargs
                 {% endif -%}
    ):
        {% if class_name != 'Entity' -%}
        super().__init__(*args, **kwargs)
        {% endif -%}
        {% for key, val in required.items() -%}
        self.{{ key }} = {{ key }}
        {% endfor -%}
        {% for key in definition.keys() -%}
        {% if 'time' in key -%}

        if {{ key }} is None or {{ key }} == '':
            self.{{ key }} = create_timestamp()
        else:
            self.{{ key }} = {{ key }}

        {% elif "ID" in key -%}
        if {{ key }} is None or {{ key }} == '':
            self.{{ key }} = str(uuid.uuid4())
        else:
            self.{{ key }} = {{ key }}

        {% elif 'name' in key -%}
        if {{ key }} is None or {{ key }} == '':
            self.{{ key }} = self.ID
        else:
            self.{{ key }} = {{ key }}

        {% elif 'comment' in key -%}
        if isinstance({{ key }}, list) and len({{ key }}) != 0:
            self.{{ key }} = []
            for com in {{ key }}:
                self.add_comment(com)
        else:
            self.{{ key }} = [].copy()

        {% elif 'data_structure' in key %}
        if isinstance({{ key }}, dict) and len([x for x in {{ key }}.keys()]) != 0:
            self.{{ key }} = {{ key }}
        else:
            self.{{ key }} = dict()

        {% elif not defaults[key] is string and defaults[key] is iterable -%}
        # If we don't save a copy of the list,
        #   python ends up assigning the same object in memory to every Entity instance.
        if isinstance({{ key }}, list) and len({{ key }}) != 0:
            self.{{ key }} = {{ key }}
        else:
            self.{{ key }} = [].copy()
        {% else -%}

        self.{{ key }} = {{ key }}
        {% endif -%}
        {% endfor -%}
        {% if class_name == 'Instance' -%}
        # If you start with data, populate itself by loading values from file system.
        if len(data) != 0:
            self.populate_itself()
        {% endif %}

    def to_TOML(self, path: Optional[Union[str,Path]] = None):

        if hasattr(super(), 'to_TOML'):
            doc = super().to_TOML()
            vals = doc[self.name]
        else:
            doc = tomlkit.document()
            vals = tomlkit.table()

        vals['type'] = self.__class__.__name__
        {% for key, val in required.items() -%}
        vals['{{ key }}'] = self.{{ key }}
        {% endfor -%}
        {% for key in definition.keys() -%}
        {% if 'children' in key -%}
        # We want to save the str version of every child, not the object.
        vals['{{ key }}'] = [str(child) for child in self.{{ key }}]
        {% elif 'parent' in key -%}
        vals['{{ key }}'] = str(self.{{ key }})
        {% elif 'comment' in key -%}
        # Same as children, we want to save the str version of every comment, not the object.
        vals['{{ key }}'] = [str(comment) for comment in self.{{ key }}]
        {% else -%}
        vals['{{ key }}'] = self.{{ key }}
        {% endif %}
        {% endfor %}
        doc[self.name] = vals

        if path is not None:
            path = Path(path)
            if path.is_dir():
                path = path.joinpath(self.name + '.toml')
            with open(path, 'w') as f:
                f.write(doc.as_string())

        return doc

    def __str__(self):
        return str(self.to_TOML())

    def __eq__(self, other):
        if isinstance(other, self.__class__):
            return self.__dict__ == other.__dict__
        return False

    {# Only add the add_children method for the Entity class and no other one. #}
    {% if class_name == 'Entity' -%}
    def add_child(self, child):
        if not hasattr(self, 'children'):
            self.children = []
        self.children.append(child)

    def add_comment(self, comment: Union[str, Comment, Table, List[Table], List[Comment], List[str]], user: Optional[str] = None) -> None:
        """
        Add a comment to the entity. If a directory is passed, this function will go through the directory and add a
        comment to every supported file in it in alphabetical order. It will **NOT** go through subdirectories.
        Whenever it iterates through a list (either if it is passed a list or goes through all of the files in a
        directory) it will call itself to add individual comments.

        :param comment: If passed a string to indicate the comment, it will create a new `Comment` object with that
            string as the comment. If its passed a list of strings, it will create a new comment for each of those strings.
            If passed a `Comment` object, it will add that comment to the entity. If passed a list of `Comment` objects,
            it will add each of those comments to the entity.
        :param user: The user that is adding the comment.
            If not passed, it will default to the use who created this entity.
        """

        # Function inside function because its very specific to adding comments and should not be called from anywhere else
        def add_directory(path: Path) -> None:
            files = [file for file in path.iterdir() if file.is_file()]
            supported_items = SupportedCommentType.__members__.keys()
            for file in sorted(files):
                if file.is_dir():
                    continue
                if file.suffix[1:] in supported_items:
                    self.add_comment(Comment(file, user))
                else:
                    continue

        if user is None:
            user = self.user

        if isinstance(comment, list):
            for com in comment:
                if isinstance(com, Comment):
                    self.comments.append(com)
                else:
                    self.add_comment(com, user)
        else:
            if isinstance(comment, Comment):
                self.comments.append(comment)
            elif isinstance(comment, str):
                try:
                    path = Path(comment)
                    if path.is_dir():
                        add_directory(path)
                    else:
                        self.comments.append(Comment(comment, user))
                # Comment may be too long to convert to path
                except OSError:
                    self.comments.append(Comment(comment, user))
            elif isinstance(comment, Table):
                self.comments.append(Comment(comment, user))
            else:
                raise TypeError(f"Comment must be a string, Table object, or a Comment object, not {type(comment)}")

    def modify_comment(self, comment_id, content, user=None):

        comment = None
        for com in self.comments:
            if com.ID == comment_id:
                comment = com
                break
        if comment is None:
            raise ValueError(f"Comment with id {comment_id} does not exist.")

        if user is None:
            user = comment.authors[-1]

        comment.modify(content=content, user=user)
        return True


    def suggest_data(self, query: str = "", min_threshold=5) -> List[str]:
        """
        Function used to suggest Instances based on a passed query.
        This function will go to any data bucket attached to this or any parent entity,
        ask all the data buckets associated with them and
        return any Instances that are starred and pass a regex match with the query.
        If no query is passed, it will return all starred Instances.

        :param query: The query to find Instances with.
        :param min_threshold: The minimum number of matches an Instance must have for the search to not
            go to parent data buckets.
        """

        def search_parents(parent, inner_matches):
            if parent is None:
                return inner_matches
            for bucket in parent.data_buckets:
                inner_matches.add(bucket.suggest_data(query))
            if len(inner_matches) < min_threshold:
                return search_parents(parent.parent, inner_matches)
            return inner_matches


        matches = set()
        for bucket in self.data_buckets:
            matches.add(bucket.suggest_data(query))

        if len(matches) < min_threshold:
            matches = search_parents(self.parent, matches)

        return matches

    def toggle_bookmark(self):
        """
        Changes the value in the bookmark field to the opposite of what it currently is.
        """
        self.bookmarked = not self.bookmarked

    def change_name(self, new_name: str):
        """
        Changes the name of the entity to the new name passed.
        """
        self.previous_names.append(self.name)
        self.name = new_name
    {% endif %}

    {# Only need to populate itself based on the files around the entity if its an Instance #}
    {% if class_name == 'Instance' -%}
    def populate_itself(self):
        """
        Populates itself based on the files around the Instance.

        Fields that this function populates are:
        * data_structure: Loads the ddh5 file with structure only and saves the structure
        * tags: Creates a tag for every .tag file in a parent folder, removes the first and last 2 characters of the tag, usually '__'
        * stored_params: Saves the path to every .json file in a parent folder
        * images: Saves the path to every .png, .jpg, and .html file in a parent folder
        * analysis: Saves the path to every .ipynb file in a parent folder

        :param data_path: The path to the data folder.
        """
        # multiple datasets can be in the same parent folder or different.
        # Keeps track of the parent folders to avoid duplicates
        revised_parents = []
        data_structure = {}
        tags = []
        stored_params = []
        images = []
        analysis = []
        for data_path in self.data:
            parent = Path(data_path).parent
            if parent not in revised_parents:
                for file in parent.rglob('*'):
                    if file.suffix == ".ddh5":
                        try:
                            dd = datadict_from_hdf5(str(file), structure_only=True)
                            specific_data_structure = {}
                            for name, value in dd.data_items():
                                full_name = name
                                if len(value["axes"]) > 0:
                                    full_name += f"[{', '.join(value['axes'])}]"
                                if value["unit"] != "":
                                    full_name += f"[{value['unit']}]"
                                specific_data_structure[full_name] = value["__shape__"]
                            data_structure[str(file.name)] = specific_data_structure
                        except Exception as e:
                            print(f'Error reading {file.name} {e}')

                    elif file.suffix == ".tag":
                        # remove the leading and ending '__'
                        tags.append(file.stem[2:-2])
                    # Assuming that any param for now its stored in a JSON file
                    elif file.suffix == ".json":
                        stored_params.append(str(file))
                    elif file.suffix == ".png" or file.suffix == ".jpg" or file.suffix == ".html":
                        images.append(str(file))
                    elif file.suffix == ".ipynb":
                        analysis.append(str(file))

        self.data_structure = data_structure
        self.tags = tags
        self.stored_params = stored_params
        self.images = images
        self.analysis = analysis

    {% endif %}